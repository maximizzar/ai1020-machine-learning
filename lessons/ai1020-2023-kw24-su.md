
- [ ] ai1020-2023-kw24-su - Mitschrift Abgeschlossen
- [ ] ai1020-2023-kw24-su - Anki notes erstellt

# Training von ML-Modellen

## Daten
- MNIST-Datensatz: 60000 + 10000 Bilder von handgeschriebenen Ziffern (0-9)
- Graustufenbilder 28x28 Pixel, 10 Klassen

## Setting
- Linearer Klassifikator wird auf MNIST trainiert
- Behandle LK als DNN mit:
	- affiner Schicht
	- Softmax-Schicht
- Welche Dimension haben W und b??

## Over Fitting
Over Fitting oder auch Überanpassung beschreibt das Problem, dass Trainingsdaten einfach nur auswendig gelernt wurden. Dies hat zur folge, dass das eigentlich zu lösende Problem nun nicht mehr gelöst wird. Somit beschreiben die Trainingsdaten das Problem nicht gut genug. 

- zu wenige Beispiele (wenige Daten)
- Beispiele nicht repräsentativ (wenig Heterogenität innerhalb der Daten)

### Generalisierung
- Gegenteil von Over Fitting
- Also: auf Trainingsdaten wird ein Modell trainiert, welches auf dem “echten” Problem genauso gut funktioniert
- Meist: gemessen über Testdaten!

### Over Fitting erkennen
- Wir benötigen einen zusätzlichen Datensatz, der das “wahre Problem” beschreibt, zusätzlich zu den Trainingsdaten
- Meist bezeichnet als Testdaten
- Modelloptimierung auf Trainingsdaten, Messung von Overfitting auf Testdaten
- Auf Testdaten wird nicht trainiert!!

### Wichtig für die Praxis
- Zielfunktionswert auf Trainingsdaten sagt NICHTS über Generalisierung aus!
- Relevant ist nur Zielfunktionswert auf Testdaten!!

